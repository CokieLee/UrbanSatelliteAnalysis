{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEv00UsMnlXU",
        "outputId": "b0be131f-5a56-48ad-bf7c-ed8e5692b826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zenodo-get\n",
            "  Downloading zenodo_get-2.0.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from zenodo-get) (2.32.4)\n",
            "Collecting wget (from zenodo-get)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from zenodo-get) (4.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from zenodo-get) (8.3.0)\n",
            "Collecting coverage>=7.8.2 (from zenodo-get)\n",
            "  Downloading coverage-7.10.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->zenodo-get) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->zenodo-get) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->zenodo-get) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->zenodo-get) (2025.8.3)\n",
            "Downloading zenodo_get-2.0.0-py3-none-any.whl (34 kB)\n",
            "Downloading coverage-7.10.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=5604bb4b0da399e508338a18eda881b6d67ed9f8649069e2cfd1cdfd1910ac18\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, coverage, zenodo-get\n",
            "Successfully installed coverage-7.10.7 wget-3.2 zenodo-get-2.0.0\n",
            "Title: EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification\n",
            "Keywords: remote sensing, earth observation, land cover classification, land use classification, satellite images, sentinel-2, machine learning, deep learning, deep convolutional neural network\n",
            "Publication date: 2018-07-22\n",
            "DOI: 10.5281/zenodo.7711810\n",
            "Total size: 94.7 MB\n",
            "\n",
            "Downloading (1/1):\n",
            "File: EuroSAT_RGB.zip (94.7 MB)\n",
            "Link: https://zenodo.org/api/records/7711810/files/EuroSAT_RGB.zip/content\n",
            "\n",
            "Checksum is correct for EuroSAT_RGB.zip. (f46e308c4d50d4bf32fedad2d3d62f3b)\n",
            "\n",
            "All specified files have been processed.\n"
          ]
        }
      ],
      "source": [
        "!pip install zenodo-get\n",
        "\n",
        "!zenodo_get 10.5281/zenodo.7711810 -g \"EuroSAT_RGB.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to your zip file\n",
        "zip_file_path = './EuroSAT_RGB.zip'\n",
        "\n",
        "\n",
        "extract_to_directory = 'extracted_files'\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_directory)\n",
        "    print(f\"Successfully extracted all contents of '{zip_file_path}' to '{extract_to_directory}'\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: '{zip_file_path}' is not a valid zip file.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Zip file '{zip_file_path}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1dMhd-_otgl",
        "outputId": "5aa860b6-feb7-4d8b-8964-3dabf2b720db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted all contents of './EuroSAT_RGB.zip' to 'extracted_files'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Gather all image file paths\n",
        "image_dir = './extracted_files/EuroSAT_RGB/'\n",
        "all_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir)]\n",
        "\n",
        "all_files = []\n",
        "labels = []\n",
        "\n",
        "for path in all_paths:\n",
        "  all_files.extend([os.path.join(path, f) for f in os.listdir(path)])\n",
        "  index = path.find('EuroSAT_RGB/')\n",
        "  if index != -1:\n",
        "      start_index = index + len('EuroSAT_RGB/')\n",
        "      result = path[start_index:]\n",
        "  else:\n",
        "      result = \"\" # Target string not found\n",
        "  labels.extend([result] * len(os.listdir(path)))\n",
        "\n",
        "# Get labels (assuming class names are part of the file paths)\n",
        "labels = [os.path.basename(os.path.dirname(f)) for f in all_files]\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Example categorical data\n",
        "categories = np.unique(labels)\n",
        "\n",
        "# Initialize and fit LabelEncoder\n",
        "le = LabelEncoder()\n",
        "encoded_labels = le.fit_transform(labels)\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "encoded_tensor = torch.tensor(encoded_labels, dtype=torch.long)\n",
        "\n",
        "print(f\"Original categories: {categories}\")\n",
        "print(f\"Encoded labels: {encoded_labels}\")\n",
        "print(f\"PyTorch tensor: {encoded_tensor}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gFoDtVOcgsB",
        "outputId": "476c9773-20a9-4766-bce9-1e35c98a1df0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original categories: ['AnnualCrop' 'Forest' 'HerbaceousVegetation' 'Highway' 'Industrial'\n",
            " 'Pasture' 'PermanentCrop' 'Residential' 'River' 'SeaLake']\n",
            "Encoded labels: [1 1 1 ... 5 5 5]\n",
            "PyTorch tensor: tensor([1, 1, 1,  ..., 5, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "# Replace 'path/to/your/image.jpg' with the actual path to your image file\n",
        "image = Image.open('./extracted_files/EuroSAT_RGB/Highway/Highway_1.jpg')\n",
        "\n",
        "# Convert the image to a NumPy array\n",
        "# For grayscale images, the array will be 2D (height, width)\n",
        "# For color images (RGB), the array will be 3D (height, width, 3)\n",
        "image_array = np.asarray(image)\n",
        "\n",
        "# Print the type and shape of the resulting NumPy array\n",
        "print(f\"Type of image_array: {type(image_array)}\")\n",
        "print(f\"Shape of image_array: {image_array.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hl1yeFfXuWH",
        "outputId": "e4155635-6143-4d5b-cc79-683cf7e04a38"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of image_array: <class 'numpy.ndarray'>\n",
            "Shape of image_array: (64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin github code"
      ],
      "metadata": {
        "id": "efy3pZMyWSqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])          # Convert PIL Image to PyTorch Tensor])\n",
        "\n",
        "train_dataset = ImageFolder(root='./extracted_files/EuroSAT_RGB', transform=transform)\n",
        "test_dataset = ImageFolder(root='./extracted_files/EuroSAT_RGB', transform=transform)\n",
        "\n"
      ],
      "metadata": {
        "id": "60TiQfXlcEal"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 10000\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,  # Adjust batch size as needed\n",
        "    shuffle=False,  # No need to shuffle for testing\n",
        "    num_workers=1   # Number of subprocesses to use for data loading (adjust based on system)\n",
        "    )"
      ],
      "metadata": {
        "id": "aWCfS4yzdB_h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "# Load the full dataset\n",
        "full_dataset = ImageFolder(root='./extracted_files/EuroSAT_RGB', transform=transform)\n",
        "\n",
        "# Get all indices and their corresponding labels\n",
        "indices = list(range(len(full_dataset)))\n",
        "labels = full_dataset.targets  # ImageFolder stores class labels here\n",
        "\n",
        "# Stratified split: 80% train, 20% test\n",
        "train_idx, test_idx = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    stratify=labels,\n",
        "    random_state=42  # for reproducibility\n",
        ")\n",
        "\n",
        "# create subsets\n",
        "train_dataset = Subset(full_dataset, train_idx)\n",
        "test_dataset = Subset(full_dataset, test_idx)\n",
        "\n",
        "# specify device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# dataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,   # shuffle during training\n",
        "    num_workers=1,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=1,\n",
        ")\n"
      ],
      "metadata": {
        "id": "vulT4dFZGRlg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# functions to show an image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "#print(images.shape)\n",
        "#print(labels.shape)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "#print(len(categories))\n",
        "\n",
        "# print labels\n",
        "#print(' '.join(f'{categories[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "mvAfL9Jph1Ez",
        "outputId": "01e9feb7-d0fc-4a26-f762-e86fa3d44ed8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # 8x8x3 input image\n",
        "        # Layer 1: Conv -> ReLU -> MaxPool\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "        # Output size after conv1 with padding: 64x64x16\n",
        "        # Output size after maxpool (2x2 kernel): 32x32x16\n",
        "\n",
        "        # Layer 2: Conv -> ReLU -> MaxPool\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        # Output size after conv2 with padding: 32x32x32\n",
        "        # Output size after maxpool (2x2 kernel): 16x16x32\n",
        "\n",
        "        # Fully connected layers\n",
        "\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 64)\n",
        "        self.transformer = nn.TransformerEncoderLayer(d_model=64, nhead=8, batch_first=True)\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "\n",
        "        # Flatten for fully connected layers\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = SimpleCNN(num_classes=10)\n",
        "print(model)\n",
        "\n",
        "# Create a dummy input tensor for an 8x8x3 image\n",
        "# PyTorch expects input in the format [batch_size, channels, height, width]\n",
        "#dummy_input = torch.randn(1, 3, 8, 8)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = SimpleCNN(num_classes=10)\n",
        "model.to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HcFZC3-dOV3",
        "outputId": "ec25ca28-c50a-4c1e-a632-eb61363f3b54"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=8192, out_features=64, bias=True)\n",
            "  (transformer): TransformerEncoderLayer(\n",
            "    (self_attn): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "    )\n",
            "    (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
            "    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout1): Dropout(p=0.1, inplace=False)\n",
            "    (dropout2): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=8192, out_features=64, bias=True)\n",
            "  (transformer): TransformerEncoderLayer(\n",
            "    (self_attn): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "    )\n",
            "    (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
            "    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout1): Dropout(p=0.1, inplace=False)\n",
            "    (dropout2): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "I84h6wHed4NI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    print('Epoch ', epoch-1, 'finished')\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "dGagxJXgd6VN",
        "outputId": "12816dfa-f3e4-4eaa-e664-a77450067834"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  -1 finished\n",
            "[1,     1] loss: 0.023\n",
            "Epoch  0 finished\n",
            "[2,     1] loss: 0.022\n",
            "Epoch  1 finished\n",
            "[3,     1] loss: 0.022\n",
            "Epoch  2 finished\n",
            "[4,     1] loss: 0.021\n",
            "Epoch  3 finished\n",
            "[5,     1] loss: 0.020\n",
            "Epoch  4 finished\n",
            "[6,     1] loss: 0.019\n",
            "Epoch  5 finished\n",
            "[7,     1] loss: 0.018\n",
            "Epoch  6 finished\n",
            "[8,     1] loss: 0.017\n",
            "Epoch  7 finished\n",
            "[9,     1] loss: 0.016\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-574835261.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './image_net.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "7CW8i-Q1JIDY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{categories[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "id": "zNkVYcwuJT4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "ac1ce3bf-38dd-48e5-d571-90b5a447ebfb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroundTruth:  AnnualCrop Industrial AnnualCrop Forest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = SimpleCNN()\n",
        "net.load_state_dict(torch.load(PATH, weights_only=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "5dDvJUcSJYQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040c73d3-e31c-4230-9c02-5211a75f0bd3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(images)"
      ],
      "metadata": {
        "id": "pQhItdwTJbkx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{categories[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "id": "oZ5zA1XHJeHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d598680-8d16-4d62-bddc-afa411909b76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:  Industrial Industrial Industrial Forest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "Y0cZKdG0JmAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d004a0c8-2ac1-4a48-91b9-ab03ab69af42"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 25 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in categories}\n",
        "total_pred = {classname: 0 for classname in categories}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[categories[label]] += 1\n",
        "            total_pred[categories[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "bWxLT5AbJo-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a010a566-d299-4779-f775-ecc34f544f03"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class: AnnualCrop is 0.2 %\n",
            "Accuracy for class: Forest is 99.5 %\n",
            "Accuracy for class: HerbaceousVegetation is 0.0 %\n",
            "Accuracy for class: Highway is 0.0 %\n",
            "Accuracy for class: Industrial is 94.4 %\n",
            "Accuracy for class: Pasture is 0.0 %\n",
            "Accuracy for class: PermanentCrop is 0.0 %\n",
            "Accuracy for class: Residential is 48.7 %\n",
            "Accuracy for class: River is 0.0 %\n",
            "Accuracy for class: SeaLake is 0.0 %\n"
          ]
        }
      ]
    }
  ]
}